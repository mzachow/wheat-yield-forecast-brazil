{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce3b5add",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Max Zachow\\anaconda3\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Libraries\"\"\"\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import groupby\n",
    "from copy import copy, deepcopy\n",
    "from sklearn.model_selection import cross_validate, LeaveOneGroupOut, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, SequentialFeatureSelector, SelectPercentile, mutual_info_regression, VarianceThreshold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, ElasticNet, BayesianRidge, Lasso\n",
    "from bias_correction import BiasCorrection, XBiasCorrection\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\"\"\"Notebook Settings\"\"\"\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"error\")\n",
    "pd.set_option('display.max_columns', 500)\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"Variables\"\"\"\n",
    "variables = [\"tmean\", \"tmax\", \"tmin\", \"rain\"]\n",
    "temp_variables = [\"tmean\", \"tmax\", \"tmin\"]\n",
    "crop_seasons = list(range(1993,2017))\n",
    "months_of_crop_season = list(range(4,11))\n",
    "homogeneous_groups = list(range(1,5))\n",
    "group_to_relative_production = {1:0.37, 2:0.23, 3:0.23, 4:0.18}\n",
    "vars_group1 = ['Tmax_Aug', 'Ltemp_July', 'Ltemp_Oct', 'Tmean_Oct', 'Rain_Sep', 'Hrainfall_Aug', 'Hrainfall_July',\n",
    "               'Tmin_Sep', 'Ltemp_May', 'Tmean_June', 'Hrainfall_May', 'Tmin_Aug', 'Htemp_Oct', 'Ltemp_June', 'Rainy_days_Sep']\n",
    "vars_group2 = ['Drought_Sep', 'Ltemp_July', 'Rainy_days_June', 'Rain_Oct', 'Drought_May', 'Drought_Oct', 'Tmean_Sep',\n",
    "               'Rainy_days_Aug', 'Tmax_Aug', 'Ltemp_June', 'Tmin_June', 'Drought_July', 'Ltemp_Aug', 'Tmin_Oct']\n",
    "vars_group3 = ['Tmin_June', 'Ltemp_Aug', 'Tmin_Aug', 'Tmax_May', 'Rainy_days_May', 'Ltemp_Sep', 'Drought_Sep', 'Ltemp_May',\n",
    "               'Rainy_days_Aug', 'Hrainfall_Sep', 'Drought_May', 'Rainy_days_July', 'Htemp_Aug', 'Hrainfall_July']\n",
    "vars_group4 = ['Tmin_Oct', 'Ltemp_June', 'Tmin_Sep', 'Rain_Oct', 'Ltemp_Aug', 'Tmax_June',\n",
    "               'Hrainfall_May', 'Ltemp_Sep', 'Tmean_May', 'Tmean_Aug', 'Hrainfall_Sep']\n",
    "variables_by_group = [vars_group1, vars_group2, vars_group3, vars_group4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8b868",
   "metadata": {},
   "source": [
    "## Content\n",
    "* [1. Read Data](#read_data)\n",
    "* [2. Bias-Adjustment](#bias_adjustment)\n",
    "* [3. Dataset Completion](#dataset_completion)\n",
    "* [4. Feature Computation](#feature_computation)\n",
    "* [5. Include Yield Data](#yield_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8af9fb2",
   "metadata": {},
   "source": [
    "### 1. Read Data <a name=\"read_data\"></a>\n",
    "We are working with two dataframes: **hindcasts** and **observations** who have the following structure.\n",
    "- **hindcasts**: Holds four hindcasts (ECMWF, UKMO, NCEP, MME) from 1993-2016. Each year, a hindcast is initialized from April to October with lead times until Oct 31. The hindcasts provide daily outputs for rainfall, mean, maximum, and minimum air temperature.\n",
    "- **observations**: Holds daily weather observations from 1993 to 2019 from April to October."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ef25a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_raw_model_data():\n",
    "    \"\"\"Reads and returns raw hindcasts from ECMWF, UKMO, NCEP and MME as one dataframe.\"\"\"\n",
    "    \n",
    "    ukmo = pd.read_csv(\"Data/Raw Hindcasts as CSV/ukmo.csv\", dtype={\"date\":str, \"group\":int}, parse_dates=[\"date\"])\n",
    "    ncep = pd.read_csv(\"Data/Raw Hindcasts as CSV/ncep.csv\", dtype={\"date\":str, \"group\":int}, parse_dates=[\"date\"])\n",
    "    ecmwf = pd.read_csv(\"Data/Raw Hindcasts as CSV/ecmwf.csv\", dtype={\"date\":str, \"group\":int}, parse_dates=[\"date\"])\n",
    "    \n",
    "    df = pd.concat([ukmo, ncep, ecmwf])\n",
    "    df = df.sort_values(by=[\"model\", \"init_month\", \"ensemble\", \"group\", \"year\", \"month\", \"date\"])\n",
    "    \n",
    "    ensemble_aggregation = (df\n",
    "                            .groupby([\"model\", \"init_month\", \"group\", \"year\", \"month\", \"date\"])\n",
    "                            .agg({\"tmean\":\"mean\", \"tmax\":\"mean\", \"tmin\":\"mean\", \"rain\":\"mean\"})\n",
    "                            .reset_index(drop=False))\n",
    "\n",
    "    multi_model_ensemble = (df\n",
    "                            .groupby([\"init_month\", \"group\", \"year\", \"month\", \"date\"])\n",
    "                            .agg({\"tmean\":\"mean\", \"tmax\":\"mean\", \"tmin\":\"mean\", \"rain\":\"mean\"})\n",
    "                            .reset_index(drop=False)\n",
    "                            .assign(model=\"MME\")\n",
    "                            .loc[:,ensemble_aggregation.columns])\n",
    "\n",
    "    hindcasts = (pd.concat([ensemble_aggregation, multi_model_ensemble])\n",
    "                 .rename(columns={\"date\":\"time\", \"group\":\"zone\"})\n",
    "                 .set_index([\"model\", \"init_month\", \"zone\", \"year\", \"month\"])\n",
    "                 .sort_index())\n",
    "    \n",
    "    return hindcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fab94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcasts = read_raw_model_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e175b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_observed_weather():\n",
    "    \"\"\"Reads and returns daily weather observations as dataframe.\"\"\"\n",
    "    \n",
    "    weather_station_to_group_id = {\"PFUN\":1, \"LOND\":2, \"CAMP\":3, \"PGRO\":4}         \n",
    "    all_files = glob.glob(\"Data/Observed Weather/*.csv\")\n",
    "    li = []\n",
    "    for _, filename in enumerate(all_files):\n",
    "        observations = pd.read_csv(filename,\n",
    "                                   usecols=[\"date\", \"rain\", \"tmax\", \"tmin\", \"tmean\", \"treatment\"], \n",
    "                                   dtype={\"date\":str}, \n",
    "                                   parse_dates=[\"date\"])\n",
    "        li.append(observations)\n",
    "        \n",
    "    observations = (pd\n",
    "                    .concat(li, axis=0, ignore_index=False)\n",
    "                    .assign(\n",
    "                        model=\"WS\", \n",
    "                        init_month=11, \n",
    "                        year=lambda x: x[\"date\"].dt.year, \n",
    "                        month=lambda x: x[\"date\"].dt.month)\n",
    "                   )\n",
    "    observations = observations.loc[(observations[\"month\"].isin(months_of_crop_season)) \n",
    "                                    & (observations[\"year\"] > 1992)].reset_index(drop=True)\n",
    "    \n",
    "    observations[\"zone\"] = observations[\"treatment\"].apply(lambda x: weather_station_to_group_id[x])\n",
    "    observations = (observations\n",
    "                    .loc[:, [\"model\", \"init_month\", \"zone\", \"year\", \"month\", \"date\", \"tmean\", \"tmax\", \"tmin\", \"rain\"]]\n",
    "                    .rename(columns={\"date\":\"time\"})\n",
    "                    .set_index([\"model\", \"init_month\", \"zone\", \"year\", \"month\"])\n",
    "                    .sort_index()\n",
    "         )\n",
    "    observations.loc[:, \"tmean\"] = observations.loc[:, \"tmean\"].fillna(observations.loc[:, \"tmean\"].mean())\n",
    "    observations.loc[:, \"tmax\"] = observations.loc[:, \"tmax\"].fillna(observations.loc[:, \"tmax\"].mean())\n",
    "    observations.loc[:, \"tmin\"] = observations.loc[:, \"tmin\"].fillna(observations.loc[:, \"tmin\"].mean())\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f408a0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = read_observed_weather()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2256a101",
   "metadata": {},
   "source": [
    "### 2. Bias-Adjustment <a name=\"bias_adjustment\"></a>\n",
    "Reference for [normal mapping](https://hess.copernicus.org/articles/21/2649/2017/) that is used for temp variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "93e639e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_mean_temperature_bias(observed, predicted, correction_method=\"normal_mapping\"):\n",
    "    \"\"\"Return bias-adjusted hindcasts as Dataframe.\"\"\"\n",
    "    \n",
    "    # GroupBy objects allow faster access to relevant subsets of climate data.\n",
    "    grouped_climate_observations = observed.groupby([\"zone\", \"year\", \"month\"])\n",
    "    grouped_climate_hindcasts = predicted.groupby([\"model\", \"init_month\", \"zone\", \"year\", \"month\"])\n",
    "    grouped_climate_hindcasts_reference = copy(grouped_climate_hindcasts)\n",
    "    li = []\n",
    "    \n",
    "    for group_idx, group_content in grouped_climate_hindcasts:\n",
    "        # Save group characteristics in intuitive variables.\n",
    "        current_model = group_content.index.get_level_values(\"model\")[0]\n",
    "        current_init_month = group_content.index.get_level_values(\"init_month\")[0]\n",
    "        current_zone = group_content.index.get_level_values(\"zone\")[0]\n",
    "        current_season = group_content.index.get_level_values(\"year\")[0]\n",
    "        current_month = group_content.index.get_level_values(\"month\")[0]\n",
    " \n",
    "        # Create calibration set of observations and hindcasts.\n",
    "        hindcasts_used_as_reference = []\n",
    "        observations_used_as_reference = []\n",
    "        for season in crop_seasons: \n",
    "            if season != current_season:\n",
    "                observation_to_be_added = (current_zone, season, current_month) \n",
    "                observations_used_as_reference.append(grouped_climate_observations.get_group(observation_to_be_added))   \n",
    "            hindcast_to_be_added = (current_model, current_init_month, current_zone, season, current_month)\n",
    "            hindcasts_used_as_reference.append(grouped_climate_hindcasts_reference.get_group(hindcast_to_be_added))\n",
    "        hindcasts_used_as_reference = pd.concat(hindcasts_used_as_reference, axis=0, ignore_index=False)\n",
    "        observations_used_as_reference = pd.concat(observations_used_as_reference, axis=0, ignore_index=False) \n",
    "        \n",
    "        # Perform bias-adjustment for temperature variables.\n",
    "        bc_tmean = BiasCorrection(observations_used_as_reference[\"tmean\"], hindcasts_used_as_reference[\"tmean\"], group_content[\"tmean\"])\n",
    "        bc_tmax = BiasCorrection(observations_used_as_reference[\"tmax\"], hindcasts_used_as_reference[\"tmax\"], group_content[\"tmax\"])\n",
    "        bc_tmin = BiasCorrection(observations_used_as_reference[\"tmin\"], hindcasts_used_as_reference[\"tmin\"], group_content[\"tmin\"])\n",
    "        group_content[\"tmean\"] = bc_tmean.correct(method=correction_method)\n",
    "        group_content[\"tmax\"] = bc_tmax.correct(method=correction_method)\n",
    "        group_content[\"tmin\"] = bc_tmin.correct(method=correction_method)\n",
    "        \n",
    "        li.append(group_content)\n",
    "        \n",
    "    result = pd.concat(li, axis=0, ignore_index=False)\n",
    "    return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8843d373",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hindcasts_temp_adjusted = adjust_mean_temperature_bias(observations, hindcasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dd5790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weather_extremes(observed, predicted):\n",
    "    \"\"\"Return DataFrame with additional columns that capture climate stress.\"\"\"\n",
    "    \n",
    "    # GroupBy objects allow faster access to relevant subsets of climate data.\n",
    "    grouped_climate_observations = observed.groupby([\"zone\", \"year\", \"month\"])\n",
    "    grouped_climate_hindcasts = predicted.groupby([\"model\", \"init_month\", \"zone\", \"year\", \"month\"])\n",
    "    li = []\n",
    "    \n",
    "    for group_idx, group_content in grouped_climate_hindcasts:\n",
    "        current_model = group_content.index.get_level_values(\"model\")[0]\n",
    "        current_init_month = group_content.index.get_level_values(\"init_month\")[0]\n",
    "        current_zone = group_content.index.get_level_values(\"zone\")[0]\n",
    "        current_season = group_content.index.get_level_values(\"year\")[0]\n",
    "        current_month = group_content.index.get_level_values(\"month\")[0]\n",
    "        \n",
    "        hindcasts_used_as_reference = []\n",
    "        observations_used_as_reference = []\n",
    "        for season in crop_seasons: \n",
    "            if season != current_season:\n",
    "                observation_to_be_added = (current_zone, season, current_month) \n",
    "                observations_used_as_reference.append(grouped_climate_observations.get_group(observation_to_be_added))   \n",
    "            hindcast_to_be_added = (current_model, current_init_month, current_zone, season, current_month)\n",
    "            hindcasts_used_as_reference.append(grouped_climate_hindcasts.get_group(hindcast_to_be_added))\n",
    "        hindcasts_used_as_reference = pd.concat(hindcasts_used_as_reference, axis=0, ignore_index=False)\n",
    "        observations_used_as_reference = pd.concat(observations_used_as_reference, axis=0, ignore_index=False) \n",
    "        \n",
    "        heat_days_in_observed = (100 * observations_used_as_reference[observations_used_as_reference[\"tmax\"] >= 32].shape[0]\n",
    "                                 / observations_used_as_reference.shape[0])\n",
    "        non_cold_days_in_observed = (100 * observations_used_as_reference[observations_used_as_reference[\"tmin\"] > 2].shape[0]\n",
    "                                     / observations_used_as_reference.shape[0])\n",
    "        rainy_days_in_observed = (100 * observations_used_as_reference[observations_used_as_reference[\"rain\"] >= 0.1].shape[0]\n",
    "                                        / observations_used_as_reference.shape[0])\n",
    "        non_drought_days_in_observed = (100 * observations_used_as_reference[observations_used_as_reference[\"rain\"] > 0].shape[0]\n",
    "                                        / observations_used_as_reference.shape[0])\n",
    "        excessive_rainfall_in_observed = (100 * observations_used_as_reference[observations_used_as_reference[\"rain\"] > 30].shape[0]\n",
    "                                          / observations_used_as_reference.shape[0])\n",
    "        \n",
    "        sorted_tmins_of_reference_hindcasts = np.sort(hindcasts_used_as_reference[\"tmin\"])\n",
    "        sorted_tmax_of_reference_hindcasts = np.sort(hindcasts_used_as_reference[\"tmax\"])[::-1]\n",
    "        sorted_rain_of_reference_hindcasts_asc = np.sort(hindcasts_used_as_reference[\"rain\"])\n",
    "        sorted_rain_of_reference_hindcasts_desc = sorted_rain_of_reference_hindcasts_asc[::-1]\n",
    "        \n",
    "        threshold_heat = np.percentile(sorted_tmax_of_reference_hindcasts, \n",
    "                                       100 - heat_days_in_observed)\n",
    "        threshold_cold = np.percentile(sorted_tmins_of_reference_hindcasts, \n",
    "                                       100 - non_cold_days_in_observed)\n",
    "        threshold_zero_rain = np.percentile(sorted_rain_of_reference_hindcasts_asc, \n",
    "                                            100 - non_drought_days_in_observed)\n",
    "        threshold_excessive_rain = np.percentile(sorted_rain_of_reference_hindcasts_desc, \n",
    "                                                 100 - excessive_rainfall_in_observed)\n",
    "        threshold_rainy_days = np.percentile(sorted_rain_of_reference_hindcasts_desc, \n",
    "                                                 100 - rainy_days_in_observed)\n",
    "        \n",
    "        \n",
    "        group_content.loc[group_content[\"rain\"] > threshold_excessive_rain, \"heavy_rain\"] = 1\n",
    "        group_content.loc[group_content[\"tmin\"] < threshold_cold, \"cold_stress\"] = 1\n",
    "        group_content.loc[group_content[\"tmax\"] >= threshold_heat, \"heat_stress\"] = 1\n",
    "        group_content = group_content.fillna(0)\n",
    "        group_content.loc[group_content[\"rain\"] > threshold_rainy_days, \"rainfall\"] = 1\n",
    "        group_content.loc[group_content[\"rain\"] < threshold_zero_rain, \"rainfall\"] = 0\n",
    "        li.append(group_content)\n",
    "        \n",
    "    result = pd.concat(li, axis=0, ignore_index=False)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a0b529",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcasts_extremes = adjust_weather_extremes(observations, hindcasts_temp_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1fdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_weather_extremes(observed):\n",
    "    \"\"\"Return DataFrame with additional columns that capture climate stress.\"\"\"\n",
    "    \n",
    "    observed = observed.copy()\n",
    "    observed.loc[observed[\"rain\"] > 30, \"heavy_rain\"] = 1\n",
    "    observed.loc[observed[\"tmin\"] <= 2, \"cold_stress\"] = 1\n",
    "    observed.loc[observed[\"tmax\"] >= 32, \"heat_stress\"] = 1\n",
    "    observed = observed.fillna(0)\n",
    "    observed.loc[observed[\"rain\"] > 0.1, \"rainfall\"] = 1\n",
    "    observed.loc[observed[\"rain\"] == 0, \"rainfall\"] = 0\n",
    "\n",
    "    return observed\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_extremes = adjust_weather_extremes(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb514342",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcasts_extremes.loc[(\"NCEP\", 5, [1,2,3,4], list(range(1993,2017)), [8,9,10]), [\"rainfall\", \"heavy_rain\", \"cold_stress\", \"heat_stress\"]].sum()\n",
    "observed_extremes.loc[(\"WS\", 11, [1,2,3,4], list(range(1993,2017)), [8,9,10]), [\"rainfall\", \"heavy_rain\", \"cold_stress\", \"heat_stress\"]].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d4f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcasts_extremes.round(2).head(3)\n",
    "observed_extremes.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141e37e",
   "metadata": {},
   "source": [
    "### 3. Dataset Completion <a name=\"dataset_completion\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141bbce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_dates_with_observations(observations, model):\n",
    "    \"\"\"Supplements past months before init_month with weather observations.\"\"\"\n",
    "    \n",
    "    model = model.copy()\n",
    "    grouped_model_output = model.groupby([\"model\", \"init_month\", \"zone\", \"year\"])\n",
    "    li=[]\n",
    "    for group_characteristics, group_content in grouped_model_output:\n",
    "        current_model = group_content.index.get_level_values(\"model\")[0]\n",
    "        current_init_month = group_content.index.get_level_values(\"init_month\")[0]\n",
    "        current_zone = group_content.index.get_level_values(\"zone\")[0]\n",
    "        current_season = group_content.index.get_level_values(\"year\")[0]\n",
    "        current_month = group_content.index.get_level_values(\"month\")[0]\n",
    "        \n",
    "        observations_for_zone_and_season = (observations\n",
    "                                            .loc[(\"WS\", 11, current_zone, current_season)])\n",
    "        observations_for_zone_and_season = (observations_for_zone_and_season\n",
    "                                            .assign(init_month=current_init_month, model=current_model)\n",
    "                                           .set_index([\"model\", \"init_month\"], append=True))\n",
    "        hindcasts_on_observations = observations_for_zone_and_season.merge(group_content, on=\"time\", how=\"left\", suffixes=(\"_ws\", \"_bcm\"))\n",
    "        hindcasts = hindcasts_on_observations.loc[:,[c for c in hindcasts_on_observations.columns if \"_ws\" not in c]]\n",
    "        hindcasts.columns = hindcasts.columns.str.rstrip(\"_bcm\")\n",
    "        hindcasts = hindcasts.set_index(\"time\")\n",
    "        observations_for_zone_and_season = observations_for_zone_and_season.set_index(\"time\")\n",
    "        combined = hindcasts.combine_first(observations_for_zone_and_season)\n",
    "        combined = (combined\n",
    "                    .reset_index(drop=False)\n",
    "                    .assign(model=current_model, init_month=current_init_month, \n",
    "                            zone=current_zone, year=current_season, month=lambda x: x[\"time\"].dt.month)\n",
    "                    .set_index([\"model\", \"init_month\", \"zone\", \"year\", \"month\"]))\n",
    "        if current_init_month == 10:\n",
    "            fully_observed = (observations_for_zone_and_season\n",
    "                              .reset_index(drop=False)\n",
    "                              .assign(model=current_model, init_month=11, zone=current_zone, year=current_season, month=lambda x:x[\"time\"].dt.month)\n",
    "                              .set_index([\"model\", \"init_month\", \"zone\", \"year\", \"month\"]))\n",
    "            li.append(fully_observed)\n",
    "        li.append(combined)\n",
    "\n",
    "    result = pd.concat(li, axis=0, ignore_index=False).sort_index()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a593c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model, zone, and year: init_month from 4 to 11, with 11 being fully observed\n",
    "climate_complete = fill_missing_dates_with_observations(observed_extremes, hindcasts_extremes) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd97928",
   "metadata": {},
   "source": [
    "### 4. Feature Computation <a name=\"feature_computation\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aeb0504",
   "metadata": {},
   "source": [
    "#### 4.1 Prepare Drought Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6012858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_drought_count(df):\n",
    "    \"\"\"Returns the number of consecutive days without rainfall\"\"\"\n",
    "    \n",
    "    df = df.copy().reset_index(drop=False)\n",
    "    df[\"new_Value\"] = 0\n",
    "    df[\"consecutives\"] = 0\n",
    "    grouped = df.groupby([\"model\", \"init_month\", \"zone\", \"year\"])\n",
    "    li = []\n",
    "    for n, gr in grouped:\n",
    "        l = []\n",
    "        for k, g in groupby(gr[\"rainfall\"]):\n",
    "            size = sum(1 for _ in g)\n",
    "            if k <= 0.1 and size >= 1:\n",
    "                l = l + [1]*size\n",
    "            else:\n",
    "                l = l + [0]*size\n",
    "        temp = pd.Series(l)\n",
    "        temp.index = gr.index\n",
    "        gr.loc[:, 'new_Value'] = temp\n",
    "       \n",
    "        a = gr.loc[:,'new_Value'] != 0\n",
    "        gr.loc[:,'consecutives'] = a.cumsum()-a.cumsum().where(~a).ffill().fillna(0).astype(int)\n",
    "        li.append(gr)\n",
    "        \n",
    "    result = pd.concat(li, axis=0, ignore_index=False)\n",
    "    result = result.drop({\"new_Value\"}, axis=1)\n",
    "    result[\"consecutives\"] = result[\"consecutives\"].apply(lambda x: multiples_of_ten_or_zero(x))\n",
    "    return result\n",
    "\n",
    "def multiples_of_ten_or_zero(x):\n",
    "    if x in list(range(10,101,10)):\n",
    "        return x/10\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fece22",
   "metadata": {},
   "outputs": [],
   "source": [
    "hindcasts_drought = prepare_drought_count(climate_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b57da7",
   "metadata": {},
   "source": [
    "#### 4.2 Compute monthly indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(model):\n",
    "    \"\"\"Compute monthly climate indices.\"\"\"\n",
    "    \n",
    "    month_conversion = {4:\"April\", 5:\"May\", 6:\"June\", 7:\"July\", 8:\"Aug\", 9:\"Sep\", 10:\"Oct\"} \n",
    "    climate_data_grouped = model.groupby([\"model\", \"init_month\", \"zone\", \"year\", \"month\"])\n",
    "    \n",
    "    li = []\n",
    "    for group_characteristics, group_content in climate_data_grouped:\n",
    "        relevant_model = \"WS\"\n",
    "        if (group_characteristics[1] <= group_characteristics[4]):\n",
    "            relevant_model = group_characteristics[0]\n",
    "\n",
    "        group_content = (group_content\n",
    "                         .groupby([\"model\", \"init_month\", \"zone\", \"year\", \"month\"])\n",
    "                         .agg({\"tmean\":\"mean\", \n",
    "                               \"tmax\":\"mean\",\n",
    "                               \"heat_stress\":\"sum\",\n",
    "                               \"tmin\":\"mean\",\n",
    "                               \"cold_stress\":\"sum\",\n",
    "                               \"rain\":\"sum\",\n",
    "                               \"heavy_rain\":\"sum\",\n",
    "                               \"rainfall\":[lambda x: x[x>0].count()],\n",
    "                               \"consecutives\":\"sum\"})\n",
    "                         .reset_index())\n",
    "        li.append(group_content)           \n",
    "\n",
    "    monthly_indices = pd.concat(li, axis=0, ignore_index=False)\n",
    "    monthly_indices.columns = [\"model\", \"init_month\", \"zone\", \"year\", \"month\", \"Tmean\", \"Tmax\", \"Htemp\", \"Tmin\", \"Ltemp\", \"Rain\", \"Hrainfall\", \"Rainy_days\", \"Drought\"]\n",
    "    monthly_indices[\"month\"] = monthly_indices[\"month\"].replace(month_conversion) \n",
    "    monthly_indices = monthly_indices.reset_index(drop=True)\n",
    "    monthly_indices = monthly_indices.pivot(index=[\"model\", \"init_month\", \"zone\", \"year\"], columns=\"month\")\n",
    "    monthly_indices.columns = [s[0] + \"_\" + s[1] for s in monthly_indices.columns]\n",
    "    monthly_indices = monthly_indices.reset_index().sort_values(by=[\"model\", \"init_month\", \"zone\", \"year\"])\n",
    "    \n",
    "    return monthly_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "206e3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_hindcast = aggregate_data(hindcasts_drought)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0399a8",
   "metadata": {},
   "source": [
    "### 5. Include Yield Data <a name=\"yield_data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4085fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yield_by_group():\n",
    "    df = pd.read_csv(\"Data/Yield/yield_by_group.csv\")\n",
    "    li = []\n",
    "    for group in [1, 2, 3, 4]:\n",
    "        cv_yield = df.loc[(df[\"zone\"] == group) & (df[\"year\"].isin(list(range(1993,2017))))].copy().reset_index(drop=True)\n",
    "        reg = LinearRegression()\n",
    "        slope_cv = reg.fit(cv_yield[\"year\"].values.reshape(-1,1), cv_yield[\"yield\"]).coef_[0]\n",
    "        \n",
    "        cv_yield[\"yield_detrended\"] = cv_yield[\"yield\"] + (slope_cv * (2016 - cv_yield[\"year\"]))\n",
    "        li.append(cv_yield)\n",
    "\n",
    "    df_cv = (pd\n",
    "             .concat(li, axis=0, ignore_index=False)\n",
    "             .sort_values(by=[\"zone\", \"year\"])\n",
    "             .reset_index(drop=True)\n",
    "             .drop([\"yield\"], axis=1)\n",
    "             .rename(columns={\"yield_detrended\":\"yield\"}))\n",
    "        \n",
    "    return df_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef2902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def national_yield():\n",
    "    df = pd.read_excel(\"Data/Yield/trend_corrected_yield_7720.xlsx\")\n",
    "    df.columns = [\"year\", \"yield\"]\n",
    "    df = df.loc[df[\"year\"].isin(list(range(1993,2017)))].reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4700fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "yield_by_group = read_yield_by_group()\n",
    "yield_national = national_yield()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0221d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cv_dataset = (features_hindcast\n",
    "                    .merge(yield_by_group.loc[:, [\"zone\", \"year\", \"yield\"]], how=\"left\", on=[\"zone\", \"year\"])\n",
    "                    .dropna()\n",
    "                    .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7f5e33",
   "metadata": {},
   "source": [
    "### 6. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19255792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_cross_validation(data, national_yield, model=\"ECMWF\", init_months_for_training=[4, 11]):\n",
    "    \"\"\"\n",
    "    Returns scores on LOO-CV.\n",
    "        Params:\n",
    "            train_df, dataframe: features and targets\n",
    "            national_yield, dataframe: trend-corrected national yield from 2001-2019\n",
    "            model, string: model to be trained on\n",
    "            permutation, list: init_months to be included in training \n",
    "        Returns:\n",
    "            result, dataframe: relative RMSE of national yield forecast by init_month \n",
    "    \"\"\"\n",
    "    \n",
    "    cv_dataset = (data.loc[data[\"model\"].isin([model, \"WS\"])]\n",
    "                  .reset_index(drop=True)\n",
    "                  .copy())\n",
    "    \n",
    "    relevant_columns = [c for c in cv_dataset.columns if c not in [\"init_month\", \"model\", \"yield\", \"month\", \"zone\"]]\n",
    "    national_forecasts_by_init_month = pd.DataFrame(data={\"init_month\":list(range(4,12)), \n",
    "                                                              \"difference\":np.zeros(8)})\n",
    "    for season in crop_seasons:\n",
    "        current_forecasts_by_init_month = pd.DataFrame(data={\"year\":np.repeat(season, 8), \n",
    "                                                              \"init_month\":list(range(4,12)), \n",
    "                                                              \"predicted\":np.zeros(8)})\n",
    "        for group in list(range(1,5)):\n",
    "            X_train = cv_dataset.loc[(cv_dataset[\"year\"] != season) \n",
    "                                        & (cv_dataset[\"init_month\"].isin(init_months_for_training)) \n",
    "                                           & (cv_dataset[\"zone\"] == group), variables_by_group[group-1]]\n",
    "            y_train = cv_dataset.loc[(cv_dataset[\"year\"] != season) \n",
    "                                        & (cv_dataset[\"init_month\"].isin(init_months_for_training))\n",
    "                                          & (cv_dataset[\"zone\"] == group), \"yield\"]\n",
    "            \n",
    "            pipeline = Pipeline([('scaler', StandardScaler()), ('var', VarianceThreshold()), \n",
    "                                 ('selector', SelectKBest(f_regression, k=7)), ('estimator', LinearRegression())])\n",
    "            reg = pipeline.fit(X_train, y_train)   \n",
    "            \n",
    "            for month_in_season in list(range(4,12)):\n",
    "                X_val = cv_dataset.loc[(cv_dataset[\"year\"] == season) \n",
    "                                     & (cv_dataset[\"init_month\"] == month_in_season)\n",
    "                                        & (cv_dataset[\"zone\"] == group), variables_by_group[group-1]]\n",
    "                \n",
    "                # make prediction \n",
    "                y_predicted = reg.predict(X_val)[0]\n",
    "                # store prediction weighted by contribution of group to national production\n",
    "                current_forecasts_by_init_month.loc[current_forecasts_by_init_month[\"init_month\"] == month_in_season, \"predicted\"] += y_predicted * group_to_relative_production[group]\n",
    "                #print(current_forecasts_by_init_month)\n",
    "        current_forecasts_by_init_month = current_forecasts_by_init_month.merge(national_yield, on=\"year\", how=\"left\")\n",
    "        current_forecasts_by_init_month[\"squared_difference\"] = ((current_forecasts_by_init_month[\"yield\"]\n",
    "                                                                   - current_forecasts_by_init_month[\"predicted\"])**2)\n",
    "        national_forecasts_by_init_month[\"difference\"] += current_forecasts_by_init_month[\"squared_difference\"]\n",
    "    \n",
    "    national_forecasts_by_init_month.loc[:, \"difference\"] /= 24\n",
    "\n",
    "    national_forecasts_by_init_month[\"difference\"] = np.round(100 * np.sqrt(national_forecasts_by_init_month[\"difference\"]) / national_yield[\"yield\"].mean(), 2)\n",
    "    national_forecasts_by_init_month = national_forecasts_by_init_month.set_index(\"init_month\").transpose()\n",
    "    \n",
    "    return national_forecasts_by_init_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b202a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"MME\", \"NCEP\", \"UKMO\", \"ECMWF\"]\n",
    "stats = [\"rRMSE_last_three_months\", \"improvement_May_Nov\"]\n",
    "performance_stats = pd.DataFrame(0, index=pd.MultiIndex.from_product([models, stats], names=['model', 'metric']), columns=[\"value\"])\n",
    "for model in models: # linear regression\n",
    "    res = kfold_cross_validation(kfold_cv_dataset, yield_national, model)\n",
    "    performance_stats.loc[(model, \"rRMSE_last_three_months\"), \"value\"] = np.round(res.loc[:,[9,10,11]].mean(axis=1).values[0], 2)\n",
    "    performance_stats.loc[(model, \"improvement_May_Nov\"), \"value\"] = np.round((res[5] - res[11]).values[0], 2)\n",
    "print(performance_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8b18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cross_validation(kfold_cv_dataset, yield_national, \"MME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6392c447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cross_validation(dataset, national_yield):\n",
    "    \"\"\"\n",
    "    Plots test results.\n",
    "        Params:\n",
    "            dataset, dataframe: features and targets from 1993-2019\n",
    "            national_yield, dataframe: trend-corrected national yield from 1993-2019\n",
    "        Returns:\n",
    "            result, dataframe: forecasts of national yield forecast by init_month, model, and year \n",
    "    \"\"\"\n",
    "    models = [\"ECMWF\", \"NCEP\", \"UKMO\", \"MME\"]\n",
    "    predictions_by_year_and_model = pd.DataFrame(data=0, \n",
    "                                                 index=pd.MultiIndex.from_product([models + [\"OBS\"], list(range(1993,2017))], names=['model', 'year']), \n",
    "                                                 columns=list(range(4, 12)))\n",
    "    print(national_yield.loc[national_yield[\"year\"].isin(list(range(1993,2017))), \"yield\"].values)\n",
    "    predictions_by_year_and_model.loc[(\"OBS\")] = np.repeat(national_yield.loc[national_yield[\"year\"].isin(list(range(1993,2017))), \"yield\"].values, 8).reshape(24,-1)\n",
    "    \n",
    "    for model in models:\n",
    "        for group in list(range(1,5)):\n",
    "            for season in list(range(1993,2017)):\n",
    "                dataset = dataset.sort_values(by=[\"year\", \"init_month\"]).reset_index(drop=True)\n",
    "                X_train = (dataset.loc[(dataset[\"init_month\"].isin(list(range(4,12)))) \n",
    "                                        & (dataset[\"zone\"] == group)\n",
    "                                           & (dataset[\"model\"].isin([model, \"WS\"]))\n",
    "                                              & (dataset[\"year\"] != season), variables_by_group[group-1]]\n",
    "                           .reset_index(drop=True).copy())\n",
    "                y_train = (dataset.loc[(dataset[\"init_month\"].isin(list(range(4,12)))) \n",
    "                                        & (dataset[\"zone\"] == group)\n",
    "                                           & (dataset[\"model\"].isin([model, \"WS\"]))\n",
    "                                              & (dataset[\"year\"] != season), \"yield\"]\n",
    "                           .reset_index(drop=True).copy())\n",
    "\n",
    "\n",
    "                reg = LinearRegression(fit_intercept=True).fit(X_train, y_train)  \n",
    "                \n",
    "                if season > 2016: continue\n",
    "                for month_in_season in list(range(4,12)):\n",
    "                    X_test = (dataset.loc[(dataset[\"zone\"] == group)\n",
    "                                          & (dataset[\"model\"] == model)\n",
    "                                             & (dataset[\"year\"] == season)\n",
    "                                               & (dataset[\"init_month\"] == month_in_season), variables_by_group[group-1]]\n",
    "                              .reset_index(drop=True).copy())\n",
    "                    # make prediction \n",
    "                    y_predicted = reg.predict(X_test) \n",
    "                    predictions_by_year_and_model.loc[(model, season), month_in_season] += y_predicted * group_to_relative_production[group]\n",
    "\n",
    "    return predictions_by_year_and_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb96929",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ((visualize_cross_validation(kfold_cv_dataset, yield_national) / 1000)\n",
    "           .round(2)\n",
    "           .stack()\n",
    "           .reset_index()\n",
    "           .rename(columns={\"level_2\":\"init_month\", 0:\"yield\"}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb284f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=results.loc[results[\"init_month\"] == 11], x=\"year\", y=\"yield\", hue=\"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
